{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Architecture\n",
    "\n",
    "A brief introduction and demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore our dataset. It's a dataset based on movies information scrapped from IMDB website and available on kaggle at:\n",
    "https://www.kaggle.com/datasets/utsh0dey/25k-movie-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie title</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>User Rating</th>\n",
       "      <th>Generes</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Plot Kyeword</th>\n",
       "      <th>Director</th>\n",
       "      <th>Top 5 Casts</th>\n",
       "      <th>Writer</th>\n",
       "      <th>year</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>$170,000,000 (estimated)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>187K</td>\n",
       "      <td>['Action', 'Drama']</td>\n",
       "      <td>After more than thirty years of service as one...</td>\n",
       "      <td>['fighter jet', 'sequel', 'u.s. navy', 'fighte...</td>\n",
       "      <td>Joseph Kosinski</td>\n",
       "      <td>['Jack Epps Jr.', 'Peter Craig', 'Tom Cruise',...</td>\n",
       "      <td>Jim Cash</td>\n",
       "      <td>-2022</td>\n",
       "      <td>/title/tt1745960/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jurassic World Dominion</td>\n",
       "      <td>2 hours 27 minutes</td>\n",
       "      <td>6</td>\n",
       "      <td>56K</td>\n",
       "      <td>['Action', 'Adventure', 'Sci-Fi']</td>\n",
       "      <td>Four years after the destruction of Isla Nubla...</td>\n",
       "      <td>['dinosaur', 'jurassic park', 'tyrannosaurus r...</td>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>['Colin Trevorrow', 'Derek Connolly', 'Chris P...</td>\n",
       "      <td>Emily Carmichael</td>\n",
       "      <td>-2022</td>\n",
       "      <td>/title/tt8041270/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top Gun</td>\n",
       "      <td>$15,000,000 (estimated)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>380K</td>\n",
       "      <td>['Action', 'Drama']</td>\n",
       "      <td>As students at the United States Navy's elite ...</td>\n",
       "      <td>['pilot', 'male camaraderie', 'u.s. navy', 'gr...</td>\n",
       "      <td>Tony Scott</td>\n",
       "      <td>['Jack Epps Jr.', 'Ehud Yonay', 'Tom Cruise', ...</td>\n",
       "      <td>Jim Cash</td>\n",
       "      <td>-1986</td>\n",
       "      <td>/title/tt0092099/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               movie title                  Run Time Rating User Rating  \\\n",
       "0        Top Gun: Maverick  $170,000,000 (estimated)    8.6        187K   \n",
       "1  Jurassic World Dominion        2 hours 27 minutes      6         56K   \n",
       "2                  Top Gun   $15,000,000 (estimated)    6.9        380K   \n",
       "\n",
       "                             Generes  \\\n",
       "0                ['Action', 'Drama']   \n",
       "1  ['Action', 'Adventure', 'Sci-Fi']   \n",
       "2                ['Action', 'Drama']   \n",
       "\n",
       "                                            Overview  \\\n",
       "0  After more than thirty years of service as one...   \n",
       "1  Four years after the destruction of Isla Nubla...   \n",
       "2  As students at the United States Navy's elite ...   \n",
       "\n",
       "                                        Plot Kyeword         Director  \\\n",
       "0  ['fighter jet', 'sequel', 'u.s. navy', 'fighte...  Joseph Kosinski   \n",
       "1  ['dinosaur', 'jurassic park', 'tyrannosaurus r...  Colin Trevorrow   \n",
       "2  ['pilot', 'male camaraderie', 'u.s. navy', 'gr...       Tony Scott   \n",
       "\n",
       "                                         Top 5 Casts            Writer   year  \\\n",
       "0  ['Jack Epps Jr.', 'Peter Craig', 'Tom Cruise',...          Jim Cash  -2022   \n",
       "1  ['Colin Trevorrow', 'Derek Connolly', 'Chris P...  Emily Carmichael  -2022   \n",
       "2  ['Jack Epps Jr.', 'Ehud Yonay', 'Tom Cruise', ...          Jim Cash  -1986   \n",
       "\n",
       "                path  \n",
       "0  /title/tt1745960/  \n",
       "1  /title/tt8041270/  \n",
       "2  /title/tt0092099/  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/unprocessed/25k-imdb-movie-dataset.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def concat_list(list_: list) -> str:\n",
    "  \"\"\"Joins with ' ' every item from the list.\"\"\"\n",
    "  list_ = literal_eval(list_)\n",
    "  return ' '.join(list_)\n",
    "\n",
    "def string_to_list(string: str) -> list:\n",
    "  \"\"\"Literal eval. for a list\"\"\"\n",
    "  list_ = literal_eval(string)\n",
    "  return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAs, clean keywords, stars, generes and ratings\n",
    "df = df.fillna(' ')\n",
    "df['Keywords'] = df['Plot Kyeword'].apply(concat_list)\n",
    "df['Stars'] = df['Top 5 Casts'].apply(concat_list)\n",
    "df['Generes'] = df['Generes'].apply(concat_list)\n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors=\"coerce\").fillna(0).astype(\"float\")\n",
    "\n",
    "# Concatenate all to have a more complete description\n",
    "df['text'] = df.apply(lambda x : str(x['Overview']) + ' ' + x['Keywords'] + ' ' + x['Stars'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop used columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Plot Kyeword','Top 5 Casts', 'Run Time', 'User Rating', 'path', 'year'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josealcocer27/.cache/pypoetry/virtualenvs/rag-architecture-QupOUSK4-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [09:08<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# You can use sentence_transformers if you have GPU, else you can use OpenAI Embeddings via API\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate Embeddings\n",
    "embeddings = model.encode(df['text'], batch_size=64, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asign Embeddings to a column\n",
    "df['embeddings'] = embeddings.tolist()\n",
    "\n",
    "# The vectorstore will need an id for every register\n",
    "df['ids'] = df.index\n",
    "df['ids'] = df['ids'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Generes</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Director</th>\n",
       "      <th>Writer</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Stars</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Action Drama</td>\n",
       "      <td>After more than thirty years of service as one...</td>\n",
       "      <td>Joseph Kosinski</td>\n",
       "      <td>Jim Cash</td>\n",
       "      <td>fighter jet sequel u.s. navy fighter aircraft ...</td>\n",
       "      <td>Jack Epps Jr. Peter Craig Tom Cruise Jennifer ...</td>\n",
       "      <td>After more than thirty years of service as one...</td>\n",
       "      <td>[-0.07095595449209213, -0.009480987675487995, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jurassic World Dominion</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Action Adventure Sci-Fi</td>\n",
       "      <td>Four years after the destruction of Isla Nubla...</td>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>Emily Carmichael</td>\n",
       "      <td>dinosaur jurassic park tyrannosaurus rex veloc...</td>\n",
       "      <td>Colin Trevorrow Derek Connolly Chris Pratt Bry...</td>\n",
       "      <td>Four years after the destruction of Isla Nubla...</td>\n",
       "      <td>[-0.025362147018313408, -0.06149573251605034, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               movie title  Rating                  Generes  \\\n",
       "0        Top Gun: Maverick     8.6             Action Drama   \n",
       "1  Jurassic World Dominion     6.0  Action Adventure Sci-Fi   \n",
       "\n",
       "                                            Overview         Director  \\\n",
       "0  After more than thirty years of service as one...  Joseph Kosinski   \n",
       "1  Four years after the destruction of Isla Nubla...  Colin Trevorrow   \n",
       "\n",
       "             Writer                                           Keywords  \\\n",
       "0          Jim Cash  fighter jet sequel u.s. navy fighter aircraft ...   \n",
       "1  Emily Carmichael  dinosaur jurassic park tyrannosaurus rex veloc...   \n",
       "\n",
       "                                               Stars  \\\n",
       "0  Jack Epps Jr. Peter Craig Tom Cruise Jennifer ...   \n",
       "1  Colin Trevorrow Derek Connolly Chris Pratt Bry...   \n",
       "\n",
       "                                                text  \\\n",
       "0  After more than thirty years of service as one...   \n",
       "1  Four years after the destruction of Isla Nubla...   \n",
       "\n",
       "                                          embeddings ids  \n",
       "0  [-0.07095595449209213, -0.009480987675487995, ...   0  \n",
       "1  [-0.025362147018313408, -0.06149573251605034, ...   1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save it\n",
    "df = pd.read_csv(\"../data/processed/embeddings_dataset.csv\")\n",
    "df['ids'] = df.index\n",
    "df['ids'] = df['ids'].astype('str')\n",
    "df['embeddings'] = df['embeddings'].apply(string_to_list)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store or Vector Database\n",
    "\n",
    "Chromadb\n",
    "\n",
    "Chroma is the open-source embedding database. Chroma makes it easy to build LLM apps by making knowledge, facts, and skills pluggable for LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate client and persist Embeddings Datatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "client_persistent = chromadb.PersistentClient(path='../data/data_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformers: open-source embeddings model\n",
    "Define Embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josealcocer27/.cache/pypoetry/virtualenvs/rag-architecture-QupOUSK4-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "sentence_transformer_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_embeddings = client_persistent.get_or_create_collection(\n",
    "    name='movies_db_embeddings', \n",
    "    embedding_function= sentence_transformer_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test reasons, We will select only top 3500 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add rows to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_embeddings.add(\n",
    "    ids=df['ids'].tolist(),\n",
    "    embeddings=df['embeddings'].tolist(),\n",
    "    metadatas=df.drop(['ids','embeddings','text'],axis=1).to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it with a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db_embeddings.query(\n",
    "    query_texts=['a history about a theft'],\n",
    "    n_results=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['2394', '1312']],\n",
       " 'distances': [[0.8909051418304443, 0.9687187075614929]],\n",
       " 'metadatas': [[{'Director': 'Brian A. Miller',\n",
       "    'Generes': 'Action Drama Thriller',\n",
       "    'Keywords': 'car stolen money gunfight firefight shot to death amnesia hidden loot gunshot wound wounded in the head head injury',\n",
       "    'Overview': 'The lone surviving thief of a violent armored car robbery is sprung from a high security facility and administered an experimental drug.',\n",
       "    'Rating': 3.8,\n",
       "    'Stars': 'Ryan Guzman Sylvester Stallone Meadow Williams Brian A. Miller Mike Maples',\n",
       "    'Writer': 'Mike Maples',\n",
       "    'movie title': 'Backtrace'},\n",
       "   {'Director': 'Gemma Mc Carthy',\n",
       "    'Generes': 'Action',\n",
       "    'Overview': 'A thief gets out of prison after many years and decides to try and locate someone from his past. After a series of events, he ends up becoming sheriff. Now he has to face his past while in his new position as sheriff.',\n",
       "    'Rating': 8.5,\n",
       "    'Stars': \"Jonathan O' Dwyer Sean Flood Frank Hurley Gemma Mc Carthy Gemma Mc Carthy\",\n",
       "    'Writer': 'Gemma Mc Carthy',\n",
       "    'movie title': 'Banshee'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Embeddings: private embeddings model\n",
    "Define Embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_function = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=openai_api_key,\n",
    "    model_name = 'text-embedding-ada-002'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mapply\n",
    "mapply.init(chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [01:42<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "def get_embedding(text: str, model: str = 'text-embedding-ada-002') -> list:\n",
    "    text = text.replace('\\n', '')\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "df[\"embeddings\"] = df[\"text\"].mapply(get_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_embeddings = client_persistent.get_or_create_collection(\n",
    "    name='movies_db_embeddings_openai', \n",
    "    embedding_function= openai_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add rows to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_embeddings.add(\n",
    "    ids=df['ids'].tolist(),\n",
    "    embeddings=df['embeddings'].tolist(),\n",
    "    metadatas=df.drop(['ids','embeddings','text'],axis=1).to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "LangChain is a framework for developing applications powered by language models. \n",
    "\n",
    "It's very useful to build RAG pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document has 15 pages\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../data/unstructured/atenttion_is_all_you_need.pdf\")\n",
    "data = loader.load()\n",
    "print(f\"This document has {len(data)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text splitters\n",
    "\n",
    "We need to break Documents into smaller chunks because is useful both, for indexing data and passing it to a model, large chunks are harder to search over and won't fit in model's context window.\n",
    "\n",
    "It's recommended chunks between 500 and 1000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 93 documents!\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    length_function=len,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(data)\n",
    "print(f\"Now we have {len(documents)} documents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Instantiate OpenAI Embeddings\n",
    "embedding_openai = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "\n",
    "# Create Vector Store with Embeddings\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents = documents,\n",
    "    embedding = embedding_openai,\n",
    "    persist_directory = \"..data/data_embeddings/attention-embeddings\"\n",
    ")\n",
    "\n",
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it with a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='The Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building', metadata={'page': 1, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  0.37473738402405193),\n",
       " (Document(page_content='language modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture', metadata={'page': 1, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  0.38047644039019496),\n",
       " (Document(page_content='7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014', metadata={'page': 9, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  0.3889431224662332),\n",
       " (Document(page_content='University of Toronto\\naidan@cs.toronto.edu≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó ‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,', metadata={'page': 0, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  0.3995172913693596),\n",
       " (Document(page_content='tion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.', metadata={'page': 1, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  0.4021886308824313)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are transformers?\"\n",
    "\n",
    "docs = vector_store.similarity_search_with_score(query, k=5)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building', metadata={'page': 1, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       " Document(page_content='language modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture', metadata={'page': 1, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       " Document(page_content='7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014', metadata={'page': 9, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       " Document(page_content='University of Toronto\\naidan@cs.toronto.edu≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó ‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,', metadata={'page': 0, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs = {\"k\":4}\n",
    ")\n",
    "query = \"What are transformers?\"\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can create a Chain to ask question based on our base knowledge (Vector Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature = 0.0\n",
    ")\n",
    "\n",
    "qa_chain_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our RAG pipeline üòé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What are transformers?',\n",
       " 'answer': 'Transformers are a type of sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. They allow for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on GPUs.\\n',\n",
       " 'sources': '../data/unstructured/atenttion_is_all_you_need.pdf',\n",
       " 'source_documents': [Document(page_content='The Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building', metadata={'page': 1, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  Document(page_content='language modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture', metadata={'page': 1, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  Document(page_content='7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014', metadata={'page': 9, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'}),\n",
       "  Document(page_content='University of Toronto\\naidan@cs.toronto.edu≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó ‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,', metadata={'page': 0, 'source': '../data/unstructured/atenttion_is_all_you_need.pdf'})]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_with_sources.invoke({\"question\":\"What are transformers?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-QupOUSK4-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
